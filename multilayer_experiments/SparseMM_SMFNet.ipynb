{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc40fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install torch_sparse, torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76158d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from two_class_data_generation import *\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import itertools\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_sparse import spmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93704149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(10)\n",
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "\n",
    "device_id = 0\n",
    "print(torch.cuda.get_device_name(device_id))\n",
    "torch.cuda.set_device(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55c12cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chord_indices_assym(n_vec, n_link):\n",
    "    \"\"\"\n",
    "    Generates the position indicies, based on the asymmetric Chord protocol (incl. itself).\n",
    "\n",
    "    :param n_vec: number of vectors (i.e. length of a sequence)\n",
    "    :param n_link: number of links in the Chord protocol\n",
    "    :return: target indices in two lists, each is of size n_vec * (n_link + 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    rows = list(\n",
    "        itertools.chain(\n",
    "            *[\n",
    "                [i for j in range(n_link + 1)] for i in range(n_vec)\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    cols = list(\n",
    "        itertools.chain(\n",
    "            *[\n",
    "                [i] + [(i + 2 ** k) % n_vec for k in range(n_link)] for i in range(n_vec)\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return rows, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05179a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMF with sparse multiplication\n",
    "\n",
    "class VIdenticalModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VIdenticalModule, self).__init__()\n",
    "\n",
    "    def forward(self, data):\n",
    "        return data\n",
    "\n",
    "    \n",
    "class WModuleSparse(nn.Module):\n",
    "    def __init__(self, n_link, n_dim, n_hidden):\n",
    "        super(WModuleSparse, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(n_dim, n_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(n_hidden, n_link + 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.network(data)\n",
    "    \n",
    "    \n",
    "class InteractionModuleSparse(nn.Module):\n",
    "    def __init__(self, n_class, n_W, n_vec, n_dim, n_link,\n",
    "                 n_hidden_f, n_hidden_v, batch_size, use_cuda):\n",
    "        super(InteractionModuleSparse, self).__init__()\n",
    "        self.n_vec = n_vec\n",
    "        self.n_dim = n_dim\n",
    "        self.n_link = n_link\n",
    "        self.batch_size = batch_size\n",
    "        self.use_cuda = use_cuda\n",
    "        self.fs = nn.ModuleList(\n",
    "            [WModuleSparse(n_link, n_dim, n_hidden_f) for i in range(n_W)]\n",
    "        )\n",
    "        self.g = VIdenticalModule()\n",
    "        self.final = nn.Linear(self.n_vec * self.n_dim, n_class, bias=True)\n",
    "        self.chord_indicies = torch.tensor(get_chord_indices_assym(n_vec, n_link))\n",
    "        if self.use_cuda:\n",
    "            self.chord_indicies = self.chord_indicies.cuda()\n",
    "    \n",
    "    def forward(self, data):\n",
    "        V = self.g(data)\n",
    "        residual = V\n",
    "        for f in self.fs[::-1]:\n",
    "            W = f(data)\n",
    "            \n",
    "            V = spmm(\n",
    "                self.chord_indicies,\n",
    "                W.reshape(W.size(0), W.size(1) * W.size(2)), \n",
    "                self.n_vec,\n",
    "                self.n_vec,\n",
    "                V\n",
    "            )\n",
    "            \n",
    "            V += residual\n",
    "            \n",
    "        V = self.final(V.view(data.size(0), -1))\n",
    "        return V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e8aeb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary functions \n",
    "\n",
    "def weights_init(module):\n",
    "    classname = module.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        torch.nn.init.normal_(module.weight, 0.0, 1e-2)\n",
    "        if hasattr(module, 'bias') and module.bias is not None:\n",
    "            torch.nn.init.normal_(module.bias, 0.0, 1e-2)\n",
    "            \n",
    "            \n",
    "class DatasetCreator(Dataset):\n",
    "    \"\"\"\n",
    "    Class to construct a dataset for training/inference\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mode, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        assert len(self.data) == len(self.labels),\\\n",
    "            \"The number of samples doesn't match the number of labels\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns: tuple (sample, target)\n",
    "        \"\"\"\n",
    "        X = data[index].unsqueeze(-1)\n",
    "        Y = labels[index].type(torch.LongTensor)\n",
    "        return (X, Y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a85de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model \n",
    "\n",
    "n_data = 12000\n",
    "n_test = 3000\n",
    "n_class = 2\n",
    "n_dim = 1\n",
    "n_hidden_f = 20\n",
    "n_hidden_v = 3\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "# For hard testing\n",
    "# n_W = 20\n",
    "# n_link = 20\n",
    "# n_vec = 1048576 # 15215MiB on GPU (batch_size=2)\n",
    "\n",
    "# For easy testing\n",
    "n_W = 7\n",
    "n_link = 7\n",
    "n_vec = 128\n",
    "\n",
    "\n",
    "net = InteractionModuleSparse(\n",
    "    n_class,\n",
    "    n_W,\n",
    "    n_vec,\n",
    "    n_dim,\n",
    "    n_link,\n",
    "    n_hidden_f,\n",
    "    n_hidden_v,\n",
    "    batch_size,\n",
    "    use_cuda=True\n",
    ")\n",
    "\n",
    "net.apply(weights_init)\n",
    "\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e23b329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing synthetic data and DataLoaders from torch_geometric\n",
    "\n",
    "data, labels = generate_two_class_data(n_data, n_vec, binary=False, same_sigma=False, xor=True)\n",
    "\n",
    "data, labels, data_val, labels_val = data[n_test:], labels[n_test:], data[:n_test], labels[:n_test]\n",
    "\n",
    "trainset = DatasetCreator(\n",
    "    mode='train',\n",
    "    data = data,\n",
    "    labels = labels\n",
    ")\n",
    "trainloader = torch_geometric.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "valset = DatasetCreator(\n",
    "    mode='test',\n",
    "    data = data_val,\n",
    "    labels = labels_val\n",
    ")\n",
    "valloader = torch_geometric.data.DataLoader(\n",
    "    valset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56e73e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def TrainSMF(\n",
    "        net,\n",
    "        trainloader,\n",
    "        valloader,\n",
    "        n_epochs,\n",
    "        test_freq,\n",
    "        optimizer,\n",
    "        loss\n",
    "):\n",
    "    losses = []\n",
    "    losses_eval = []\n",
    "    accuracies = []\n",
    "    for epoch in range(n_epochs):\n",
    "        # Training\n",
    "        running_loss = 0\n",
    "        for i, (X, Y) in enumerate(trainloader):\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            pred = net(X)\n",
    "            output = loss(pred, Y)\n",
    "            output.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += output.item()\n",
    "\n",
    "        print(\"Epoch {} - Training loss:   {}\".format(epoch, running_loss / len(trainloader)))\n",
    "        losses.append(float(running_loss / len(trainloader)))\n",
    "        \n",
    "        # Validation\n",
    "        if epoch % test_freq == 0:\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                val_loss = 0.0\n",
    "                for i, (X, Y) in enumerate(valloader):\n",
    "                    X = X.cuda()\n",
    "                    Y = Y.cuda()\n",
    "                    pred = net(X)\n",
    "                    val_loss += loss(pred, Y).item()\n",
    "                    \n",
    "                    _, predicted = torch.max(pred.data, 1)\n",
    "                    total += Y.size(0)\n",
    "                    correct += (predicted == Y).sum().item()\n",
    "                    \n",
    "            print(\"Epoch {} - Validation loss: {}\".format(epoch, val_loss / len(valloader)))\n",
    "            print('Accuracy of the network: %d %%' % (100 * correct / total))\n",
    "            print('_' * 40)\n",
    "            losses_eval.append(float(val_loss / len(valloader)))\n",
    "            accuracies.append(100 * correct / total)\n",
    "            net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f03ad22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss:   0.175665405727729\n",
      "Epoch 0 - Validation loss: 0.0\n",
      "Accuracy of the network: 100 %\n",
      "________________________________________\n",
      "Epoch 1 - Training loss:   0.00012022578612306884\n",
      "Epoch 1 - Validation loss: 0.0\n",
      "Accuracy of the network: 100 %\n",
      "________________________________________\n",
      "Epoch 2 - Training loss:   1.8671005086468757e-05\n",
      "Epoch 2 - Validation loss: 0.0\n",
      "Accuracy of the network: 100 %\n",
      "________________________________________\n",
      "Epoch 3 - Training loss:   7.71473871469376e-06\n",
      "Epoch 3 - Validation loss: 0.0\n",
      "Accuracy of the network: 100 %\n",
      "________________________________________\n",
      "Epoch 4 - Training loss:   3.948551455512156e-06\n",
      "Epoch 4 - Validation loss: 0.0\n",
      "Accuracy of the network: 100 %\n",
      "________________________________________\n",
      "Epoch 5 - Training loss:   2.254952220853331e-06\n",
      "Epoch 5 - Validation loss: 0.0\n",
      "Accuracy of the network: 100 %\n",
      "________________________________________\n",
      "Epoch 6 - Training loss:   1.428618442482272e-06\n",
      "Epoch 6 - Validation loss: 0.0\n",
      "Accuracy of the network: 100 %\n",
      "________________________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c0dcd230ec72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtest_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-32-083c7a001413>\u001b[0m in \u001b[0;36mTrainSMF\u001b[0;34m(net, trainloader, valloader, n_epochs, test_freq, optimizer, loss)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-0917bb7206bc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             )\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch_sparse/spmm.py\u001b[0m in \u001b[0;36mspmm\u001b[0;34m(index, value, m, n, matrix)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter_add\u001b[0;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 dim_size: Optional[int] = None) -> torch.Tensor:\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter_sum\u001b[0;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "TrainSMF(\n",
    "    net=net,\n",
    "    trainloader=trainloader,\n",
    "    valloader=valloader,\n",
    "    n_epochs=10,\n",
    "    test_freq=1,\n",
    "    optimizer=optimizer,\n",
    "    loss=loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e739f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
