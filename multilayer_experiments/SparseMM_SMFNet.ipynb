{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91228706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install torch_sparse, torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c15a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from two_class_data_generation import *\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import itertools\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_sparse import spmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3ac0586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(10)\n",
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "\n",
    "device_id = 0\n",
    "print(torch.cuda.get_device_name(device_id))\n",
    "torch.cuda.set_device(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3308c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chord_indices_assym(n_vec, n_link):\n",
    "    \"\"\"\n",
    "    Generates the position indicies, based on the asymmetric Chord protocol (incl. itself).\n",
    "\n",
    "    :param n_vec: number of vectors (i.e. length of a sequence)\n",
    "    :param n_link: number of links in the Chord protocol\n",
    "    :return: target indices in two lists, each is of size n_vec * (n_link + 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    rows = list(\n",
    "        itertools.chain(\n",
    "            *[\n",
    "                [i for j in range(n_link + 1)] for i in range(n_vec)\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    cols = list(\n",
    "        itertools.chain(\n",
    "            *[\n",
    "                [i] + [(i + 2 ** k) % n_vec for k in range(n_link)] for i in range(n_vec)\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return rows, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0858392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMF with sparse multiplication\n",
    "\n",
    "class VIdenticalModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VIdenticalModule, self).__init__()\n",
    "\n",
    "    def forward(self, data):\n",
    "        return data\n",
    "\n",
    "    \n",
    "class WModuleSparse(nn.Module):\n",
    "    def __init__(self, n_link, n_dim, n_hidden):\n",
    "        super(WModuleSparse, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(n_dim, n_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(n_hidden, n_link + 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.network(data)\n",
    "    \n",
    "    \n",
    "class InteractionModuleSparse(nn.Module):\n",
    "    def __init__(self, n_class, n_W, n_vec, n_dim, n_link,\n",
    "                 n_hidden_f, n_hidden_v, batch_size, use_cuda):\n",
    "        super(InteractionModuleSparse, self).__init__()\n",
    "        self.n_vec = n_vec\n",
    "        self.n_dim = n_dim\n",
    "        self.n_link = n_link\n",
    "        self.batch_size = batch_size\n",
    "        self.use_cuda = use_cuda\n",
    "        self.fs = nn.ModuleList(\n",
    "            [WModuleSparse(n_link, n_dim, n_hidden_f) for i in range(n_W)]\n",
    "        )\n",
    "        self.g = VIdenticalModule()\n",
    "        self.final = nn.Linear(self.n_vec * self.n_dim, n_class, bias=True)\n",
    "        self.chord_indicies = torch.tensor(get_chord_indices_assym(n_vec, n_link))\n",
    "        if self.use_cuda:\n",
    "            self.chord_indicies = self.chord_indicies.cuda()\n",
    "    \n",
    "    def forward(self, data):\n",
    "#         if self.cuda:\n",
    "#             data = data.cuda()\n",
    "        V = self.g(data)\n",
    "        residual = V\n",
    "        for f in self.fs[::-1]:\n",
    "            W = f(data)\n",
    "            \n",
    "            V = spmm(\n",
    "                self.chord_indicies,\n",
    "                W.reshape(W.size(0), W.size(1) * W.size(2)), \n",
    "                self.n_vec,\n",
    "                self.n_vec,\n",
    "                V\n",
    "            )\n",
    "            V += residual\n",
    "            \n",
    "        V = self.final(V.view(data.size(0), -1))\n",
    "        return V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ab29960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary functions \n",
    "\n",
    "def weights_init(module):\n",
    "    classname = module.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        torch.nn.init.normal_(module.weight, 0.0, 1e-2)\n",
    "        if hasattr(module, 'bias') and module.bias is not None:\n",
    "            torch.nn.init.normal_(module.bias, 0.0, 1e-2)\n",
    "            \n",
    "            \n",
    "class DatasetCreator(Dataset):\n",
    "    \"\"\"\n",
    "    Class to construct a dataset for training/inference\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mode, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        assert len(self.data) == len(self.labels),\\\n",
    "            \"The number of samples doesn't match the number of labels\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns: tuple (sample, target)\n",
    "        \"\"\"\n",
    "        X = data[index].unsqueeze(-1)\n",
    "        Y = labels[index].type(torch.LongTensor)\n",
    "        return (X, Y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f92f1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model \n",
    "\n",
    "n_data = 12000\n",
    "n_test = 3000\n",
    "n_class = 2\n",
    "n_dim = 1\n",
    "n_hidden_f = 20\n",
    "n_hidden_v = 3\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "# For hard testing\n",
    "# n_W = 20\n",
    "# n_link = 20\n",
    "# n_vec = 1048576 # 15215MiB on GPU (batch_size=2)\n",
    "\n",
    "# For easy testing\n",
    "n_W = 7\n",
    "n_link = 7\n",
    "n_vec = 128\n",
    "\n",
    "\n",
    "net = InteractionModuleSparse(\n",
    "    n_class,\n",
    "    n_W,\n",
    "    n_vec,\n",
    "    n_dim,\n",
    "    n_link,\n",
    "    n_hidden_f,\n",
    "    n_hidden_v,\n",
    "    batch_size,\n",
    "    use_cuda=True\n",
    ")\n",
    "\n",
    "net.apply(weights_init)\n",
    "\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a90c92bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing synthetic data and DataLoaders from torch_geometric\n",
    "\n",
    "data, labels = generate_two_class_data(n_data, n_vec, binary=False, same_sigma=False, xor=True)\n",
    "\n",
    "data, labels, data_val, labels_val = data[n_test:], labels[n_test:], data[:n_test], labels[:n_test]\n",
    "\n",
    "trainset = DatasetCreator(\n",
    "    mode='train',\n",
    "    data = data,\n",
    "    labels = labels\n",
    ")\n",
    "trainloader = torch_geometric.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "valset = DatasetCreator(\n",
    "    mode='test',\n",
    "    data = data_val,\n",
    "    labels = labels_val\n",
    ")\n",
    "valloader = torch_geometric.data.DataLoader(\n",
    "    valset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "904839b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def TrainSMF(\n",
    "        net,\n",
    "        trainloader,\n",
    "        valloader,\n",
    "        n_epochs,\n",
    "        test_freq,\n",
    "        optimizer,\n",
    "        loss\n",
    "):\n",
    "    losses = []\n",
    "    losses_eval = []\n",
    "    accuracies = []\n",
    "    for epoch in range(n_epochs):\n",
    "        # Training\n",
    "        running_loss = 0\n",
    "        for i, (X, Y) in enumerate(trainloader):\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            pred = net(X)\n",
    "            output = loss(pred, Y)\n",
    "            output.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += output.item()\n",
    "\n",
    "        print(\"Epoch {} - Training loss:   {}\".format(epoch, running_loss / len(trainloader)))\n",
    "        losses.append(float(running_loss / len(trainloader)))\n",
    "        \n",
    "        # Validation\n",
    "        if epoch % test_freq == 0:\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                val_loss = 0.0\n",
    "                for i, (X, Y) in enumerate(valloader):\n",
    "                    X = X.cuda()\n",
    "                    Y = Y.cuda()\n",
    "                    pred = net(X)\n",
    "                    val_loss += loss(pred, Y).item()\n",
    "                    \n",
    "                    _, predicted = torch.max(pred.data, 1)\n",
    "                    total += Y.size(0)\n",
    "                    correct += (predicted == Y).sum().item()\n",
    "                    \n",
    "            print(\"Epoch {} - Validation loss: {}\".format(epoch, val_loss / len(valloader)))\n",
    "            print('Accuracy of the network: %d %%' % (100 * correct / total))\n",
    "            print('_' * 40)\n",
    "            losses_eval.append(float(val_loss / len(valloader)))\n",
    "            accuracies.append(100 * correct / total)\n",
    "            net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30343aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss:   0.6541194513108995\n",
      "Epoch 0 - Validation loss: 1.0018336772918701\n",
      "Accuracy of the network: 0 %\n",
      "________________________________________\n",
      "Epoch 1 - Training loss:   0.6374050671524472\n",
      "Epoch 1 - Validation loss: 1.076012372970581\n",
      "Accuracy of the network: 0 %\n",
      "________________________________________\n",
      "Epoch 2 - Training loss:   0.6366049136718114\n",
      "Epoch 2 - Validation loss: 1.093941330909729\n",
      "Accuracy of the network: 0 %\n",
      "________________________________________\n",
      "Epoch 3 - Training loss:   0.636584500140614\n",
      "Epoch 3 - Validation loss: 1.1082909107208252\n",
      "Accuracy of the network: 0 %\n",
      "________________________________________\n",
      "Epoch 4 - Training loss:   0.6365858999225829\n",
      "Epoch 4 - Validation loss: 1.0924708843231201\n",
      "Accuracy of the network: 0 %\n",
      "________________________________________\n",
      "Epoch 5 - Training loss:   0.6366091051366594\n",
      "Epoch 5 - Validation loss: 1.10152268409729\n",
      "Accuracy of the network: 0 %\n",
      "________________________________________\n",
      "Epoch 6 - Training loss:   0.636634212732315\n",
      "Epoch 6 - Validation loss: 1.1048147678375244\n",
      "Accuracy of the network: 0 %\n",
      "________________________________________\n",
      "Epoch 7 - Training loss:   0.6365841587384542\n",
      "Epoch 7 - Validation loss: 1.1017354726791382\n",
      "Accuracy of the network: 0 %\n",
      "________________________________________\n",
      "Epoch 8 - Training loss:   0.6365843788120482\n",
      "Epoch 8 - Validation loss: 1.0965101718902588\n",
      "Accuracy of the network: 0 %\n",
      "________________________________________\n",
      "Epoch 9 - Training loss:   0.6365882056951523\n",
      "Epoch 9 - Validation loss: 1.092339277267456\n",
      "Accuracy of the network: 0 %\n",
      "________________________________________\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "TrainSMF(\n",
    "    net=net,\n",
    "    trainloader=trainloader,\n",
    "    valloader=valloader,\n",
    "    n_epochs=10,\n",
    "    test_freq=1,\n",
    "    optimizer=optimizer,\n",
    "    loss=loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9711a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
